while True:
	frame=flux_video.read() # retourne un boolean true si la frame est bien lu
    rgb=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB) #convertie la video de BGR en RGB
    rgb=imutils.resize(frame,width=750) #redimensionne la fenêtre avec une largueur de 750
    r=frame.shape [1] / float(rgb.shape [1]) # .shape  renvoie la taille de la frame.
    boxes=face_recognition.face_locations(rgb,model=args["detection_method"]) #détecte la délimitation du visage
    encodings=face_recognition.face_encodings(rgb,boxes) # encode pour chaque visage detecter
    names=[] #initialisation tableau de nom qu'on a detecter

    for encoding in encodings:
        matches=face_recognition.compare_faces(data["encodings"],encoding)
        if True in matches:
            matchedIdxs=[i for(i,b)in enumerate(matches) if b]
            counts={}
            for i in matchedIdxs:
                name=data["names"][i]
                counts[name]=counts.get(name,0)+1
            name=max(counts,key=counts.get)
        else:
            name=unknown
        names.append(name)
        	# loop over the recognized faces
	    for ((top, right, bottom, left), name) in zip(boxes, names):
		# rescale the face coordinates
		    top = int(top * r)
		    right = int(right * r)
		    bottom = int(bottom * r)
		    left = int(left * r)
		# draw the predicted face name on the image
		    cv2.rectangle(frame, (left, top), (right, bottom),(0, 255, 0), 2)
            y = top - 15 if top - 15 > 15 else top + 15
		    cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)
    if args["display"]>0:
        cv2.imshow("Frame",frame)
        key=cv2.waitKey(1) & 0xFF
        if key == ord("q"):
            break
cv2.destroyAllWindows()
flux_video.stop()














